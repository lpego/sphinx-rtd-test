<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Classification: finetune &mdash; mzbsuite 0.0.1 alpha documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Processing scripts" href="../scripts/processing_scripts.html" />
    <link rel="prev" title="Classification: inference" href="classification_inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            mzbsuite
              <img src="../../_static/mzbsuite_logo_v2.1.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Project Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflow_models.html">Workflow and Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Configuration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="segmentation.html">Image segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="skeletonization_unsupervised.html">Skeletonization unsupervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="skeletonization_supervised_inference.html">Skeletonization: supervised, inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification_inference.html">Classification: inference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Classification: finetune</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Processing scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scripts/processing_scripts.html">Processing scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripts/diverse_preprocessing.html">Other scripts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">mzb-suite Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/mzbsuite.html"><code class="docutils literal notranslate"><span class="pre">mzbsuite</span></code> module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/mzbsuite.html#functions-and-docstrings">Functions and docstrings</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">mzbsuite</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Classification: finetune</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/files/examples/classification_finetune.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Classification:-finetune">
<h1>Classification: finetune<a class="headerlink" href="#Classification:-finetune" title="Permalink to this heading"></a></h1>
<p>In this notebook we illustrate how to re-train the models on user’s data. Specifically, we remap the last layer of the model to the desired classes, without modifying the model’s internal weights; this operation is called finetuning and is not as computationally intensive as re-training the full model. Regardless, this module greatly benefits from GPU compute, as long as the GPU(s) support CUDA and <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> is configured correctly.</p>
<p>This module uses two scripts: <code class="docutils literal notranslate"><span class="pre">classification/main_prepare_learning_sets.py</span></code> for preparing the data for training, and <code class="docutils literal notranslate"><span class="pre">classification/main_classification_finetune.py</span></code>, that need to be executed in that order.</p>
<p>The first step is to import the necessary libraries for <code class="docutils literal notranslate"><span class="pre">main_prepare_learning_sets.py</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="kn">from</span> <span class="nn">mzbsuite.utils</span> <span class="kn">import</span> <span class="n">cfg_to_arguments</span>
</pre></div>
</div>
</div>
<p>We need to declare the running parameters for the script,</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ROOT_DIR</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span>
<span class="n">MODEL</span><span class="o">=</span><span class="s2">&quot;convnext-small-vtest-1&quot;</span>
<span class="n">LSET_FOLD</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ROOT_DIR</span><span class="si">}</span><span class="s2">/data/mzb_example_data&quot;</span>

<span class="n">arguments</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;input_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;/data/shared/mzb-workflow/data/learning_sets/project_portable_flume/curated_learning_sets&quot;</span><span class="p">,</span>
    <span class="s2">&quot;taxonomy_file&quot;</span><span class="p">:</span> <span class="n">ROOT_DIR</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;data/MZB_taxonomy.csv&quot;</span><span class="p">,</span>
    <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="n">ROOT_DIR</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;data/mzb_example_data/aggregated_learning_sets&quot;</span><span class="p">,</span>
    <span class="s2">&quot;save_model&quot;</span><span class="p">:</span> <span class="n">ROOT_DIR</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;models/mzb-classification-models/</span><span class="si">{</span><span class="n">MODEL</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="s2">&quot;config_file&quot;</span><span class="p">:</span> <span class="n">ROOT_DIR</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;configs/configuration_flume_datasets.yaml&quot;</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">arguments</span><span class="p">[</span><span class="s2">&quot;config_file&quot;</span><span class="p">]),</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">Loader</span><span class="o">=</span><span class="n">yaml</span><span class="o">.</span><span class="n">FullLoader</span><span class="p">)</span>

<span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;trcl_gpu_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># this sets the number of available GPUs to zero, since this part of the module doesn&#39;t benefit from GPU compute.</span>
<span class="n">cfg</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;glob_random_seed&#39;: 222,
 &#39;glob_root_folder&#39;: &#39;/data/users/luca/mzb-workflow/mzb-workflow/&#39;,
 &#39;glob_blobs_folder&#39;: &#39;/data/users/luca/mzb-workflow/mzb-workflow/data/derived/blobs/&#39;,
 &#39;glob_local_format&#39;: &#39;pdf&#39;,
 &#39;model_logger&#39;: &#39;wandb&#39;,
 &#39;impa_image_format&#39;: &#39;jpg&#39;,
 &#39;impa_clip_areas&#39;: [2750, 4900],
 &#39;impa_area_threshold&#39;: 5000,
 &#39;impa_gaussian_blur&#39;: [21, 21],
 &#39;impa_gaussian_blur_passes&#39;: 3,
 &#39;impa_adaptive_threshold_block_size&#39;: 351,
 &#39;impa_mask_postprocess_kernel&#39;: [11, 11],
 &#39;impa_mask_postprocess_passes&#39;: 5,
 &#39;impa_bounding_box_buffer&#39;: 200,
 &#39;impa_save_clips_plus_features&#39;: True,
 &#39;lset_class_cut&#39;: &#39;order&#39;,
 &#39;lset_val_size&#39;: 0.1,
 &#39;lset_taxonomy&#39;: &#39;/data/users/luca/mzb-workflow/data/MZB_taxonomy.csv&#39;,
 &#39;trcl_learning_rate&#39;: 0.001,
 &#39;trcl_batch_size&#39;: 16,
 &#39;trcl_weight_decay&#39;: 0,
 &#39;trcl_step_size_decay&#39;: 5,
 &#39;trcl_number_epochs&#39;: 10,
 &#39;trcl_save_topk&#39;: 1,
 &#39;trcl_num_classes&#39;: 8,
 &#39;trcl_model_pretrarch&#39;: &#39;efficientnet-b2&#39;,
 &#39;trcl_num_workers&#39;: 16,
 &#39;trcl_wandb_project_name&#39;: &#39;mzb-classifiers&#39;,
 &#39;trcl_logger&#39;: &#39;wandb&#39;,
 &#39;trsk_learning_rate&#39;: 0.001,
 &#39;trsk_batch_size&#39;: 32,
 &#39;trsk_weight_decay&#39;: 0,
 &#39;trsk_step_size_decay&#39;: 25,
 &#39;trsk_number_epochs&#39;: 400,
 &#39;trsk_save_topk&#39;: 1,
 &#39;trsk_num_classes&#39;: 2,
 &#39;trsk_model_pretrarch&#39;: &#39;mit_b2&#39;,
 &#39;trsk_num_workers&#39;: 16,
 &#39;trsk_wandb_project_name&#39;: &#39;mzb-skeletons&#39;,
 &#39;trsk_logger&#39;: &#39;wandb&#39;,
 &#39;infe_model_ckpt&#39;: &#39;last&#39;,
 &#39;infe_num_classes&#39;: 8,
 &#39;infe_image_glob&#39;: &#39;*_rgb.jpg&#39;,
 &#39;skel_class_exclude&#39;: &#39;errors&#39;,
 &#39;skel_conv_rate&#39;: 131.6625,
 &#39;skel_label_thickness&#39;: 3,
 &#39;skel_label_buffer_on_preds&#39;: 25,
 &#39;skel_label_clip_with_mask&#39;: False,
 &#39;trcl_gpu_ids&#39;: None}
</pre></div></div>
</div>
<p>Convert these parameters to a dictionary:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Transforms configurations dicts to argparse arguments</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">cfg_to_arguments</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg_to_arguments</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;glob_random_seed&#39;: 222, &#39;glob_root_folder&#39;: &#39;/data/users/luca/mzb-workflow/mzb-workflow/&#39;, &#39;glob_blobs_folder&#39;: &#39;/data/users/luca/mzb-workflow/mzb-workflow/data/derived/blobs/&#39;, &#39;glob_local_format&#39;: &#39;pdf&#39;, &#39;model_logger&#39;: &#39;wandb&#39;, &#39;impa_image_format&#39;: &#39;jpg&#39;, &#39;impa_clip_areas&#39;: [2750, 4900], &#39;impa_area_threshold&#39;: 5000, &#39;impa_gaussian_blur&#39;: [21, 21], &#39;impa_gaussian_blur_passes&#39;: 3, &#39;impa_adaptive_threshold_block_size&#39;: 351, &#39;impa_mask_postprocess_kernel&#39;: [11, 11], &#39;impa_mask_postprocess_passes&#39;: 5, &#39;impa_bounding_box_buffer&#39;: 200, &#39;impa_save_clips_plus_features&#39;: True, &#39;lset_class_cut&#39;: &#39;order&#39;, &#39;lset_val_size&#39;: 0.1, &#39;lset_taxonomy&#39;: &#39;/data/users/luca/mzb-workflow/data/MZB_taxonomy.csv&#39;, &#39;trcl_learning_rate&#39;: 0.001, &#39;trcl_batch_size&#39;: 16, &#39;trcl_weight_decay&#39;: 0, &#39;trcl_step_size_decay&#39;: 5, &#39;trcl_number_epochs&#39;: 10, &#39;trcl_save_topk&#39;: 1, &#39;trcl_num_classes&#39;: 8, &#39;trcl_model_pretrarch&#39;: &#39;efficientnet-b2&#39;, &#39;trcl_num_workers&#39;: 16, &#39;trcl_wandb_project_name&#39;: &#39;mzb-classifiers&#39;, &#39;trcl_logger&#39;: &#39;wandb&#39;, &#39;trsk_learning_rate&#39;: 0.001, &#39;trsk_batch_size&#39;: 32, &#39;trsk_weight_decay&#39;: 0, &#39;trsk_step_size_decay&#39;: 25, &#39;trsk_number_epochs&#39;: 400, &#39;trsk_save_topk&#39;: 1, &#39;trsk_num_classes&#39;: 2, &#39;trsk_model_pretrarch&#39;: &#39;mit_b2&#39;, &#39;trsk_num_workers&#39;: 16, &#39;trsk_wandb_project_name&#39;: &#39;mzb-skeletons&#39;, &#39;trsk_logger&#39;: &#39;wandb&#39;, &#39;infe_model_ckpt&#39;: &#39;last&#39;, &#39;infe_num_classes&#39;: 8, &#39;infe_image_glob&#39;: &#39;*_rgb.jpg&#39;, &#39;skel_class_exclude&#39;: &#39;errors&#39;, &#39;skel_conv_rate&#39;: 131.6625, &#39;skel_label_thickness&#39;: 3, &#39;skel_label_buffer_on_preds&#39;: 25, &#39;skel_label_clip_with_mask&#39;: False, &#39;trcl_gpu_ids&#39;: None}
</pre></div></div>
</div>
<p>We next check whether the target directories already exist, and if not create them:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">glob_random_seed</span><span class="p">)</span>

<span class="c1"># root of raw clip data</span>
<span class="n">root_data</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">input_dir</span><span class="p">)</span>
<span class="n">outdir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
<span class="n">outdir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># target folders definition</span>
<span class="n">target_trn</span> <span class="o">=</span> <span class="n">outdir</span> <span class="o">/</span> <span class="s2">&quot;trn_set/&quot;</span>
<span class="n">target_val</span> <span class="o">=</span> <span class="n">outdir</span> <span class="o">/</span> <span class="s2">&quot;val_set/&quot;</span>

<span class="c1"># check if trn_set and val_set subfolders exist. If so, then interrupt the script.</span>
<span class="c1"># This is to make sure that no overwriting happens; prompt the user that they need to specify a different output directory.</span>
<span class="k">if</span> <span class="n">target_trn</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span> <span class="ow">or</span> <span class="n">target_val</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="c1"># print in red and back to normal</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[91m Output directory </span><span class="si">{</span><span class="n">outdir</span><span class="si">}</span><span class="s2"> already exists. Please specify a different output directory.</span><span class="se">\033</span><span class="s2">[0m&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<p>We now use the specified taxonomic rank in the <code class="docutils literal notranslate"><span class="pre">lset_class_cut</span></code> parameter in the configuration file to cut the provided phylogenetic tree, and reorganize the images in directories corresponding to the this rank. See the documentation for further details.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="c1"># make dictionary to recode: key is current classification, value is target reclassification.</span>
<span class="c1"># forward fill to get last valid entry and subset to desired column</span>
<span class="n">mzb_taxonomy</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">taxonomy_file</span><span class="p">))</span>
<span class="k">if</span> <span class="s2">&quot;Unnamed: 0&quot;</span> <span class="ow">in</span> <span class="n">mzb_taxonomy</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">mzb_taxonomy</span> <span class="o">=</span> <span class="n">mzb_taxonomy</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Unnamed: 0&quot;</span><span class="p">])</span>
<span class="n">mzb_taxonomy</span> <span class="o">=</span> <span class="n">mzb_taxonomy</span><span class="o">.</span><span class="n">ffill</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">recode_order</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="nb">zip</span><span class="p">(</span><span class="n">mzb_taxonomy</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">],</span> <span class="n">mzb_taxonomy</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">lset_class_cut</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cutting phylogenetic tree at: </span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">lset_class_cut</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cutting phylogenetic tree at: order
</pre></div></div>
</div>
<p>Now we copy the images over into the new folder structure according to the taxonomy:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Move files to target folders for all files in the curated learning set</span>
<span class="k">for</span> <span class="n">s_fo</span> <span class="ow">in</span> <span class="n">recode_order</span><span class="p">:</span>
    <span class="n">target_folder</span> <span class="o">=</span> <span class="n">target_trn</span> <span class="o">/</span> <span class="n">recode_order</span><span class="p">[</span><span class="n">s_fo</span><span class="p">]</span>
    <span class="n">target_folder</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">((</span><span class="n">root_data</span> <span class="o">/</span> <span class="n">s_fo</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)):</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">target_folder</span><span class="p">)</span>

<span class="c1"># move out the validation set</span>
<span class="c1"># make a small val set, 10% or 1 file, what is possible...</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">lset_val_size</span>
<span class="n">trn_folds</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">target_trn</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)))]</span>
<br/></pre></div>
</div>
</div>
<p>Next, we split the validation set based on the proportion of total images specified by the <code class="docutils literal notranslate"><span class="pre">lset_val_size</span></code> parameter in the configuration file. We recommend at least 10% of the total images for each class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="k">for</span> <span class="n">s_fo</span> <span class="ow">in</span> <span class="n">trn_folds</span><span class="p">:</span>
    <span class="n">target_folder</span> <span class="o">=</span> <span class="n">target_val</span> <span class="o">/</span> <span class="n">s_fo</span>
    <span class="n">target_folder</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">list_class</span> <span class="o">=</span> <span class="nb">list</span><span class="p">((</span><span class="n">target_trn</span> <span class="o">/</span> <span class="n">s_fo</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">))</span>
    <span class="n">n_val_sam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_class</span><span class="p">))))</span>

    <span class="n">val_files</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">list_class</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_val_sam</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">val_files</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">),</span> <span class="n">target_folder</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="si">}</span><span class="s2"> into </span><span class="si">{</span><span class="n">target_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
/data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/trn_set/errors/32_hf2_plecoptera_01_clip_8_rgb.jpg into /data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/val_set/errors
/data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/trn_set/errors/32_ob_leuctridae_01_clip_4_rgb.jpg into /data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/val_set/errors
/data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/trn_set/plecoptera/32_bd_plecoptera_01_clip_2_rgb.jpg into /data/users/luca/mzb-workflow/data/mzb_example_data/aggregated_learning_sets/val_set/plecoptera
</pre></div></div>
</div>
<p>Now we have the training dataset ready for model training, with a training set and a validation set containing the same classes.</p>
<p>We move on to the model finetuning, using the script <code class="docutils literal notranslate"><span class="pre">classification/main_classification_finetune.py</span></code>. First we import some additional libraries from PyTorch;</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">WandbLogger</span><span class="p">,</span> <span class="n">TensorBoardLogger</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.ddp</span> <span class="kn">import</span> <span class="n">DDPStrategy</span>

<span class="kn">from</span> <span class="nn">mzbsuite.classification.mzb_classification_pilmodel</span> <span class="kn">import</span> <span class="n">MZBModel</span>
<span class="kn">from</span> <span class="nn">mzbsuite.utils</span> <span class="kn">import</span> <span class="n">cfg_to_arguments</span><span class="p">,</span> <span class="n">SaveLogCallback</span>

<span class="c1"># Set the thread layer used by MKL</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MKL_THREADING_LAYER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;GNU&quot;</span> <span class="c1"># this time we set the GPU computing layer to active</span>
</pre></div>
</div>
</div>
<p>Before we can launch the training, we need to define a few special parameters, relating to finding the specified monitoring the model training progress over time:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define checkpoints callbacks</span>
<span class="c1"># best model on validation</span>
<span class="n">best_val_cb</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">dirpath</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;best-val-</span><span class="si">{epoch}</span><span class="s2">-</span><span class="si">{step}</span><span class="s2">-</span><span class="si">{val_loss:.1f}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="n">save_top_k</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_save_topk</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># latest model in training</span>
<span class="n">last_mod_cb</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">dirpath</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;last-</span><span class="si">{step}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">every_n_train_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">save_top_k</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_save_topk</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define progress bar callback</span>
<span class="n">pbar_cb</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">TQDMProgressBar</span><span class="p">(</span><span class="n">refresh_rate</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Define logger callback to log training date</span>
<span class="n">trdatelog</span> <span class="o">=</span> <span class="n">SaveLogCallback</span><span class="p">(</span><span class="n">model_folder</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">)</span>

<span class="c1"># Define model from config</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MZBModel</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">input_dir</span><span class="p">,</span>
    <span class="n">pretrained_network</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_model_pretrarch</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_learning_rate</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_batch_size</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_weight_decay</span><span class="p">,</span>
    <span class="n">num_workers_loader</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_num_workers</span><span class="p">,</span>
    <span class="n">step_size_decay</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_step_size_decay</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_num_classes</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We now check wether a pre-trained model is available, and if there is load the weights from that model. Note that logging model progress requires either a <a class="reference external" href="https://wandb.ai/">Weights &amp; Biases</a> or <a class="reference external" href="https://www.tensorflow.org/">Tensorflow</a> account. See the documentation for more details.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if there is a model to load, if there is, load it and train from there</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model from </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fmodel</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;last-*.ckpt&quot;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No last-* model in folder, loading best model&quot;</span><span class="p">)</span>
        <span class="n">fmodel</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;best-val-epoch=*-step=*-val_loss=*.*.ckpt&quot;</span><span class="p">)</span>
        <span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">fmodel</span><span class="p">)</span>

<span class="c1"># Define logger and name of run</span>
<span class="n">name_run</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;classifier-</span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_model_pretrarch</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># f&quot;{model.pretrained_network}&quot;</span>
<span class="n">cbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">pbar_cb</span><span class="p">,</span> <span class="n">best_val_cb</span><span class="p">,</span> <span class="n">last_mod_cb</span><span class="p">,</span> <span class="n">trdatelog</span><span class="p">]</span>

<span class="c1"># Define logger, and use either wandb or tensorboard</span>
<span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">trcl_logger</span> <span class="o">==</span> <span class="s2">&quot;wandb&quot;</span><span class="p">:</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">WandbLogger</span><span class="p">(</span>
        <span class="n">project</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_wandb_project_name</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_run</span> <span class="k">if</span> <span class="n">name_run</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

<span class="k">elif</span> <span class="n">cfg</span><span class="o">.</span><span class="n">trcl_logger</span> <span class="o">==</span> <span class="s2">&quot;tensorboard&quot;</span><span class="p">:</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">TensorBoardLogger</span><span class="p">(</span>
        <span class="n">save_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name_run</span> <span class="k">if</span> <span class="n">name_run</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Currently logged in as: <span class="ansi-yellow-fg">lpego</span> (<span class="ansi-yellow-fg">biodetect</span>). Use <span class="ansi-bold">`wandb login --relogin`</span> to force relogin
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
wandb version 0.16.0 is available!  To upgrade, please run:
 $ pip install wandb --upgrade</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Tracking run with wandb version 0.15.4</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Run data is saved locally in <code>./wandb/run-20231111_161213-1u2u0o5h</code></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Syncing run <strong><a href='https://wandb.ai/biodetect/mzb-classifiers/runs/1u2u0o5h' target="_blank">classifier-efficientnet-b2</a></strong> to <a href='https://wandb.ai/biodetect/mzb-classifiers' target="_blank">Weights & Biases</a> (<a href='https://wandb.me/run' target="_blank">docs</a>)<br/></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
View project at <a href='https://wandb.ai/biodetect/mzb-classifiers' target="_blank">https://wandb.ai/biodetect/mzb-classifiers</a></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
View run at <a href='https://wandb.ai/biodetect/mzb-classifiers/runs/1u2u0o5h' target="_blank">https://wandb.ai/biodetect/mzb-classifiers/runs/1u2u0o5h</a></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: logging graph, to disable use `wandb.watch(log_graph=False)`
</pre></div></div>
</div>
<p>We are now finally ready to train our model!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="c1"># instantiate trainer and train</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># cfg.trcl_num_gpus outdated</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">trcl_number_epochs</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="n">DDPStrategy</span><span class="p">(</span>
        <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">),</span>  <span class="c1"># TODO: check how to use in notebook</span>
    <span class="n">precision</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">cbacks</span><span class="p">,</span>
    <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">1</span>
    <span class="c1"># profiler=&quot;simple&quot;,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/luca/mambaforge/envs/mzbsuite/lib/python3.10/site-packages/lightning_fabric/connector.py:555: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
  rank_zero_warn(
Using 16bit Automatic Mixed Precision (AMP)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">MisconfigurationException</span>                 Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb Cell 22</span> line <span class="ansi-cyan-fg">2
</span><span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0&#39;&gt;1&lt;/a&gt;</span> # instantiate trainer and train
<span class="ansi-green-fg">----&gt; &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1&#39;&gt;2&lt;/a&gt;</span> trainer = pl.Trainer(
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2&#39;&gt;3&lt;/a&gt;</span>     accelerator=&#34;auto&#34;,  # cfg.trcl_num_gpus outdated
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3&#39;&gt;4&lt;/a&gt;</span>     max_epochs=cfg.trcl_number_epochs,
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4&#39;&gt;5&lt;/a&gt;</span>     strategy=DDPStrategy(
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5&#39;&gt;6&lt;/a&gt;</span>         find_unused_parameters=False
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6&#39;&gt;7&lt;/a&gt;</span>     ),  # TODO: check how to use in notebook
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7&#39;&gt;8&lt;/a&gt;</span>     precision=16,
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8&#39;&gt;9&lt;/a&gt;</span>     callbacks=cbacks,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9&#39;&gt;10&lt;/a&gt;</span>     logger=logger,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10&#39;&gt;11&lt;/a&gt;</span>     log_every_n_steps=1
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11&#39;&gt;12&lt;/a&gt;</span>     # profiler=&#34;simple&#34;,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12&#39;&gt;13&lt;/a&gt;</span> )
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://ssh-remote%2Bbiodetectgpu.datascience.ch/data/users/luca/mzb-workflow/notebooks/classification_finetune.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14&#39;&gt;15&lt;/a&gt;</span> trainer.fit(model)

File <span class="ansi-green-fg">~/mambaforge/envs/mzbsuite/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:69</span>, in <span class="ansi-cyan-fg">_defaults_from_env_vars.&lt;locals&gt;.insert_env_defaults</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     66</span> kwargs = dict(list(env_variables.items()) + list(kwargs.items()))
<span class="ansi-green-intense-fg ansi-bold">     68</span> # all args were already moved to kwargs
<span class="ansi-green-fg">---&gt; 69</span> return fn(self, **kwargs)

File <span class="ansi-green-fg">~/mambaforge/envs/mzbsuite/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:398</span>, in <span class="ansi-cyan-fg">Trainer.__init__</span><span class="ansi-blue-fg">(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)</span>
<span class="ansi-green-intense-fg ansi-bold">    395</span> # init connectors
<span class="ansi-green-intense-fg ansi-bold">    396</span> self._data_connector = _DataConnector(self)
<span class="ansi-green-fg">--&gt; 398</span> self._accelerator_connector = _AcceleratorConnector(
<span class="ansi-green-intense-fg ansi-bold">    399</span>     devices=devices,
<span class="ansi-green-intense-fg ansi-bold">    400</span>     accelerator=accelerator,
<span class="ansi-green-intense-fg ansi-bold">    401</span>     strategy=strategy,
<span class="ansi-green-intense-fg ansi-bold">    402</span>     num_nodes=num_nodes,
<span class="ansi-green-intense-fg ansi-bold">    403</span>     sync_batchnorm=sync_batchnorm,
<span class="ansi-green-intense-fg ansi-bold">    404</span>     benchmark=benchmark,
<span class="ansi-green-intense-fg ansi-bold">    405</span>     use_distributed_sampler=use_distributed_sampler,
<span class="ansi-green-intense-fg ansi-bold">    406</span>     deterministic=deterministic,
<span class="ansi-green-intense-fg ansi-bold">    407</span>     precision=precision,
<span class="ansi-green-intense-fg ansi-bold">    408</span>     plugins=plugins,
<span class="ansi-green-intense-fg ansi-bold">    409</span> )
<span class="ansi-green-intense-fg ansi-bold">    410</span> self._logger_connector = _LoggerConnector(self)
<span class="ansi-green-intense-fg ansi-bold">    411</span> self._callback_connector = _CallbackConnector(self)

File <span class="ansi-green-fg">~/mambaforge/envs/mzbsuite/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:173</span>, in <span class="ansi-cyan-fg">_AcceleratorConnector.__init__</span><span class="ansi-blue-fg">(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)</span>
<span class="ansi-green-intense-fg ansi-bold">    170</span> self.precision_plugin = self._check_and_init_precision()
<span class="ansi-green-intense-fg ansi-bold">    172</span> # 6. Instantiate Strategy - Part 2
<span class="ansi-green-fg">--&gt; 173</span> self._lazy_init_strategy()

File <span class="ansi-green-fg">~/mambaforge/envs/mzbsuite/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:577</span>, in <span class="ansi-cyan-fg">_AcceleratorConnector._lazy_init_strategy</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    574</span> self.strategy._configure_launcher()
<span class="ansi-green-intense-fg ansi-bold">    576</span> if _IS_INTERACTIVE and self.strategy.launcher and not self.strategy.launcher.is_interactive_compatible:
<span class="ansi-green-fg">--&gt; 577</span>     raise MisconfigurationException(
<span class="ansi-green-intense-fg ansi-bold">    578</span>         f&#34;`Trainer(strategy={self._strategy_flag!r})` is not compatible with an interactive&#34;
<span class="ansi-green-intense-fg ansi-bold">    579</span>         &#34; environment. Run your code as a script, or choose one of the compatible strategies:&#34;
<span class="ansi-green-intense-fg ansi-bold">    580</span>         f&#34; `Fabric(strategy=&#39;dp&#39;|&#39;ddp_notebook&#39;)`.&#34;
<span class="ansi-green-intense-fg ansi-bold">    581</span>         &#34; In case you are spawning processes yourself, make sure to include the Trainer&#34;
<span class="ansi-green-intense-fg ansi-bold">    582</span>         &#34; creation inside the worker function.&#34;
<span class="ansi-green-intense-fg ansi-bold">    583</span>     )
<span class="ansi-green-intense-fg ansi-bold">    585</span> # TODO: should be moved to _check_strategy_and_fallback().
<span class="ansi-green-intense-fg ansi-bold">    586</span> # Current test check precision first, so keep this check here to meet error order
<span class="ansi-green-intense-fg ansi-bold">    587</span> if isinstance(self.accelerator, TPUAccelerator) and not isinstance(
<span class="ansi-green-intense-fg ansi-bold">    588</span>     self.strategy, (SingleTPUStrategy, XLAStrategy)
<span class="ansi-green-intense-fg ansi-bold">    589</span> ):

<span class="ansi-red-fg">MisconfigurationException</span>: `Trainer(strategy=&lt;pytorch_lightning.strategies.ddp.DDPStrategy object at 0x7f16508311b0&gt;)` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: `Fabric(strategy=&#39;dp&#39;|&#39;ddp_notebook&#39;)`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.
</pre></div></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="classification_inference.html" class="btn btn-neutral float-left" title="Classification: inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../scripts/processing_scripts.html" class="btn btn-neutral float-right" title="Processing scripts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-08-01 Michele Volpi, Luca Pegoraro, Blake Matthews, Catherine Graham.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>